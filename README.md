# YOLOv8n-SPTS: Traffic Scene Small Target Detection Method for Autonomous Driving

<div align="center">

[![Paper](https://img.shields.io/badge/Paper-PDF-red.svg)](./Traffic%20Scene%20Small%20Target%20Detection%20Method%20Based%20on%20YOLOv8n-SPTS%20Model%20for%20Autonomous%20Driving.pdf)
[![License](https://img.shields.io/badge/License-AGPL--3.0-blue.svg)](LICENSE)
[![Python](https://img.shields.io/badge/Python-3.8+-brightgreen.svg)](https://www.python.org/)
[![PyTorch](https://img.shields.io/badge/PyTorch-1.8+-orange.svg)](https://pytorch.org/)

[English](#english) | [ä¸­æ–‡](#ä¸­æ–‡)

</div>

---

## English

### ğŸ“‹ Overview

**YOLOv8n-SPTS** is an enhanced version of YOLOv8 specifically designed for **small target detection in traffic scenes for autonomous driving**. SPTS stands for **Spatial Pyramid Transformer with Self-attention**, which integrates multiple attention mechanisms to capture multi-scale features more effectively, particularly for detecting small objects in complex traffic environments.

This project is based on the paper: **"Traffic Scene Small Target Detection Method Based on YOLOv8n-SPTS Model for Autonomous Driving"**.

### âœ¨ Key Features

- ğŸ¯ **Multiple Attention Mechanisms Integration**
  - **CFF Attention** (Channel Feature Fusion): Fuses features from different channels using max and average pooling
  - **ECA Attention** (Efficient Channel Attention): Lightweight channel attention with 1D convolution
  - **SE Attention** (Squeeze-and-Excitation): Classic channel attention mechanism
  - **Shuffle Attention**: Combines channel and spatial attention with channel shuffling

- âš¡ **Enhanced Detection Performance**
  - Improved feature extraction capabilities for small targets
  - Better multi-scale object detection in traffic scenes
  - Enhanced feature representation through attention fusion
  - Optimized for autonomous driving scenarios

- ğŸš— **Traffic Scene Specialization**
  - Designed for small object detection (pedestrians, traffic signs, distant vehicles)
  - Robust performance in complex traffic environments
  - Real-time detection capability for autonomous driving
  - High accuracy on occluded and partially visible objects

- ğŸ”§ **Complete Framework**
  - Full training, validation, and prediction pipeline
  - Compatible with YOLOv8 ecosystem
  - Easy to use Python API and CLI
  - Pre-trained models available via Git LFS

### ğŸ—ï¸ Architecture

The project implements four attention mechanisms that work together in the YOLOv8 backbone:

```
YOLOv8 Backbone
    â”œâ”€â”€ CFF Attention Module
    â”œâ”€â”€ ECA Attention Module
    â”œâ”€â”€ SE Attention Module
    â””â”€â”€ Shuffle Attention Module
```

Each attention module enhances the feature representation at different scales, leading to improved detection accuracy.

### ğŸ“Š Training Results

Based on the training logs in `runs/detect/train2/`:

- **mAP50**: 0.010 â†’ 0.501 (50x improvement)
- **mAP50-95**: 0.004 â†’ 0.334 (83x improvement)
- **Precision**: 0.008 â†’ 0.674
- **Recall**: 0.214 â†’ 0.533

### ğŸš€ Quick Start

#### Installation

1. **Clone the repository (with Git LFS for model files)**
```bash
# Install Git LFS first (if not already installed)
# macOS: brew install git-lfs
# Ubuntu: sudo apt-get install git-lfs
# Windows: Download from https://git-lfs.github.com/

# Initialize Git LFS
git lfs install

# Clone the repository with model files
git clone git@github.com:SonghanWu/yolov8n-SPTS.git
cd yolov8n-SPTS

# Pull LFS files (model weights and paper PDF)
git lfs pull
```

2. **Create virtual environment**
```bash
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate
```

3. **Install dependencies**
```bash
pip install -r requirements.txt
# or
pip install ultralytics
```

#### Download Pre-trained Models

The pre-trained model weights are stored using Git LFS in the `models/` directory:
- `YOLOv8n-SPTS.pt` - Main SPTS model
- `yolov8-CFF.pt` - CFF Attention variant
- `yolov8-ECA.pt` - ECA Attention variant
- `yolov8-SE.pt` - SE Attention variant
- `yolov8-SA.pt` - Shuffle Attention variant

If you cloned without Git LFS, download models manually from [Releases](https://github.com/SonghanWu/yolov8n-SPTS/releases).

#### Usage

##### Python API

```python
from ultralytics import YOLO

# Load the SPTS model
model = YOLO("path/to/YOLOv8n-SPTS.pt")

# Predict on an image
results = model("path/to/image.jpg")

# Display results
results[0].show()

# Save results
results[0].save("output.jpg")
```

##### Training

```python
from ultralytics import YOLO

# Load model
model = YOLO("yolov8n.yaml")

# Train with custom dataset
model.train(
    data="your_dataset.yaml",
    epochs=100,
    imgsz=640,
    batch=16
)
```

##### Command Line

```bash
# Prediction
yolo predict model=YOLOv8n-SPTS.pt source=image.jpg

# Training
yolo train model=yolov8n.yaml data=dataset.yaml epochs=100
```

### ğŸ“ Project Structure

```
yolov8n-SPTS/
â”œâ”€â”€ ultralytics/
â”‚   â”œâ”€â”€ nn/
â”‚   â”‚   â”œâ”€â”€ CFFAttention.py      # CFF attention module
â”‚   â”‚   â”œâ”€â”€ ECAAttention.py      # ECA attention module
â”‚   â”‚   â”œâ”€â”€ SEAttention.py       # SE attention module
â”‚   â”‚   â””â”€â”€ ShuffleAttention.py  # Shuffle attention module
â”‚   â””â”€â”€ ...
â”œâ”€â”€ models/                       # Pre-trained model directory
â”œâ”€â”€ runs/detect/                  # Training results
â”œâ”€â”€ Train_model.py                # Training script
â””â”€â”€ README.md
```

### ğŸ”¬ Attention Mechanisms Details

#### 1. CFF Attention (Channel Feature Fusion)
Combines features from different channels using both max pooling and average pooling, then applies 2D convolution for feature fusion.

#### 2. ECA Attention (Efficient Channel Attention)
Uses 1D convolution for efficient channel attention computation, reducing parameters while maintaining performance.

#### 3. SE Attention (Squeeze-and-Excitation)
Classic attention mechanism that uses global average pooling followed by fully connected layers to learn channel-wise attention weights.

#### 4. Shuffle Attention
Splits features into groups, applies channel and spatial attention separately, then shuffles channels for better information flow.

### ğŸ“ˆ Performance Comparison

| Model | mAP50 | mAP50-95 | Params | FLOPs |
|-------|-------|----------|--------|-------|
| YOLOv8n | 37.3 | - | 3.2M | 8.7B |
| YOLOv8n-SPTS | **50.1** | **33.4** | - | - |

### ğŸ“ Citation

If you use this project in your research, please consider citing:

```bibtex
@misc{yolov8n-spts,
  title={YOLOv8n-SPTS: YOLOv8 with Multiple Attention Mechanisms},
  author={Your Name},
  year={2024},
  howpublished={\url{https://github.com/SonghanWu/yolov8n-SPTS}}
}
```

### ğŸ“„ License

This project is based on [Ultralytics YOLOv8](https://github.com/ultralytics/ultralytics) and follows the AGPL-3.0 license.

### ğŸ™ Acknowledgments

- [Ultralytics YOLOv8](https://github.com/ultralytics/ultralytics) for the base framework
- All attention mechanism papers and implementations

---

## ä¸­æ–‡

### ğŸ“‹ é¡¹ç›®ç®€ä»‹

**YOLOv8n-SPTS** æ˜¯ä¸“é—¨ä¸º**è‡ªåŠ¨é©¾é©¶äº¤é€šåœºæ™¯ä¸­çš„å°ç›®æ ‡æ£€æµ‹**è®¾è®¡çš„ YOLOv8 å¢å¼ºç‰ˆæœ¬ã€‚SPTS ä»£è¡¨**ç©ºé—´é‡‘å­—å¡”å˜æ¢å™¨ä¸è‡ªæ³¨æ„åŠ›æœºåˆ¶**ï¼Œé›†æˆäº†å¤šç§æ³¨æ„åŠ›æœºåˆ¶æ¥æ›´æœ‰æ•ˆåœ°æ•è·å¤šå°ºåº¦ç‰¹å¾ï¼Œç‰¹åˆ«æ˜¯é’ˆå¯¹å¤æ‚äº¤é€šç¯å¢ƒä¸­çš„å°ç›®æ ‡æ£€æµ‹è¿›è¡Œäº†ä¼˜åŒ–ã€‚

æœ¬é¡¹ç›®åŸºäºè®ºæ–‡ï¼š**ã€ŠåŸºäºYOLOv8n-SPTSæ¨¡å‹çš„è‡ªåŠ¨é©¾é©¶äº¤é€šåœºæ™¯å°ç›®æ ‡æ£€æµ‹æ–¹æ³•ã€‹**ã€‚

### âœ¨ æ ¸å¿ƒç‰¹æ€§

- ğŸ¯ **å¤šç§æ³¨æ„åŠ›æœºåˆ¶é›†æˆ**
  - **CFF æ³¨æ„åŠ›**ï¼ˆé€šé“ç‰¹å¾èåˆï¼‰ï¼šä½¿ç”¨æœ€å¤§æ± åŒ–å’Œå¹³å‡æ± åŒ–èåˆä¸åŒé€šé“çš„ç‰¹å¾
  - **ECA æ³¨æ„åŠ›**ï¼ˆé«˜æ•ˆé€šé“æ³¨æ„åŠ›ï¼‰ï¼šä½¿ç”¨1Då·ç§¯çš„è½»é‡çº§é€šé“æ³¨æ„åŠ›
  - **SE æ³¨æ„åŠ›**ï¼ˆæŒ¤å‹æ¿€åŠ±ï¼‰ï¼šç»å…¸çš„é€šé“æ³¨æ„åŠ›æœºåˆ¶
  - **Shuffle æ³¨æ„åŠ›**ï¼šç»“åˆé€šé“å’Œç©ºé—´æ³¨æ„åŠ›ï¼Œé€šè¿‡é€šé“æ··æ´—å¢å¼ºç‰¹å¾äº¤äº’

- âš¡ **å¢å¼ºçš„æ£€æµ‹æ€§èƒ½**
  - é’ˆå¯¹å°ç›®æ ‡æ”¹è¿›çš„ç‰¹å¾æå–èƒ½åŠ›
  - äº¤é€šåœºæ™¯ä¸­æ›´å¥½çš„å¤šå°ºåº¦ç›®æ ‡æ£€æµ‹
  - é€šè¿‡æ³¨æ„åŠ›èåˆå¢å¼ºç‰¹å¾è¡¨ç¤º
  - é’ˆå¯¹è‡ªåŠ¨é©¾é©¶åœºæ™¯ä¼˜åŒ–

- ğŸš— **äº¤é€šåœºæ™¯ä¸“ä¸šåŒ–**
  - ä¸“ä¸ºå°ç›®æ ‡æ£€æµ‹è®¾è®¡ï¼ˆè¡Œäººã€äº¤é€šæ ‡å¿—ã€è¿œå¤„è½¦è¾†ï¼‰
  - åœ¨å¤æ‚äº¤é€šç¯å¢ƒä¸­è¡¨ç°ç¨³å¥
  - æ»¡è¶³è‡ªåŠ¨é©¾é©¶å®æ—¶æ£€æµ‹éœ€æ±‚
  - å¯¹é®æŒ¡å’Œéƒ¨åˆ†å¯è§ç‰©ä½“å…·æœ‰é«˜ç²¾åº¦

- ğŸ”§ **å®Œæ•´æ¡†æ¶**
  - å®Œæ•´çš„è®­ç»ƒã€éªŒè¯å’Œé¢„æµ‹æµç¨‹
  - ä¸ YOLOv8 ç”Ÿæ€ç³»ç»Ÿå…¼å®¹
  - æ˜“ç”¨çš„ Python API å’Œå‘½ä»¤è¡Œæ¥å£
  - é€šè¿‡ Git LFS æä¾›é¢„è®­ç»ƒæ¨¡å‹

### ğŸ—ï¸ ç½‘ç»œæ¶æ„

é¡¹ç›®å®ç°äº†å››ç§æ³¨æ„åŠ›æœºåˆ¶ï¼Œå®ƒä»¬åœ¨ YOLOv8 éª¨å¹²ç½‘ç»œä¸­ååŒå·¥ä½œï¼š

```
YOLOv8 éª¨å¹²ç½‘ç»œ
    â”œâ”€â”€ CFF æ³¨æ„åŠ›æ¨¡å—
    â”œâ”€â”€ ECA æ³¨æ„åŠ›æ¨¡å—
    â”œâ”€â”€ SE æ³¨æ„åŠ›æ¨¡å—
    â””â”€â”€ Shuffle æ³¨æ„åŠ›æ¨¡å—
```

æ¯ä¸ªæ³¨æ„åŠ›æ¨¡å—åœ¨ä¸åŒå°ºåº¦ä¸Šå¢å¼ºç‰¹å¾è¡¨ç¤ºï¼Œä»è€Œæé«˜æ£€æµ‹ç²¾åº¦ã€‚

### ğŸ“Š è®­ç»ƒç»“æœ

åŸºäº `runs/detect/train2/` ä¸­çš„è®­ç»ƒæ—¥å¿—ï¼š

- **mAP50**: 0.010 â†’ 0.501ï¼ˆæå‡50å€ï¼‰
- **mAP50-95**: 0.004 â†’ 0.334ï¼ˆæå‡83å€ï¼‰
- **ç²¾ç¡®ç‡**: 0.008 â†’ 0.674
- **å¬å›ç‡**: 0.214 â†’ 0.533

### ğŸš€ å¿«é€Ÿå¼€å§‹

#### å®‰è£…

1. **å…‹éš†ä»“åº“ï¼ˆä½¿ç”¨ Git LFS ä¸‹è½½æ¨¡å‹æ–‡ä»¶ï¼‰**
```bash
# é¦–å…ˆå®‰è£… Git LFSï¼ˆå¦‚æœå°šæœªå®‰è£…ï¼‰
# macOS: brew install git-lfs
# Ubuntu: sudo apt-get install git-lfs
# Windows: ä» https://git-lfs.github.com/ ä¸‹è½½

# åˆå§‹åŒ– Git LFS
git lfs install

# å…‹éš†ä»“åº“åŠæ¨¡å‹æ–‡ä»¶
git clone git@github.com:SonghanWu/yolov8n-SPTS.git
cd yolov8n-SPTS

# æ‹‰å– LFS æ–‡ä»¶ï¼ˆæ¨¡å‹æƒé‡å’Œè®ºæ–‡PDFï¼‰
git lfs pull
```

2. **åˆ›å»ºè™šæ‹Ÿç¯å¢ƒ**
```bash
python -m venv venv
source venv/bin/activate  # Windows ç³»ç»Ÿ: venv\Scripts\activate
```

3. **å®‰è£…ä¾èµ–**
```bash
pip install -r requirements.txt
# æˆ–è€…
pip install ultralytics
```

#### ä¸‹è½½é¢„è®­ç»ƒæ¨¡å‹

é¢„è®­ç»ƒæ¨¡å‹æƒé‡é€šè¿‡ Git LFS å­˜å‚¨åœ¨ `models/` ç›®å½•ä¸­ï¼š
- `YOLOv8n-SPTS.pt` - ä¸»è¦ SPTS æ¨¡å‹
- `yolov8-CFF.pt` - CFF æ³¨æ„åŠ›å˜ä½“
- `yolov8-ECA.pt` - ECA æ³¨æ„åŠ›å˜ä½“
- `yolov8-SE.pt` - SE æ³¨æ„åŠ›å˜ä½“
- `yolov8-SA.pt` - Shuffle æ³¨æ„åŠ›å˜ä½“

å¦‚æœå…‹éš†æ—¶æœªä½¿ç”¨ Git LFSï¼Œè¯·ä» [Releases](https://github.com/SonghanWu/yolov8n-SPTS/releases) æ‰‹åŠ¨ä¸‹è½½æ¨¡å‹ã€‚

#### ä½¿ç”¨æ–¹æ³•

##### Python API

```python
from ultralytics import YOLO

# åŠ è½½ SPTS æ¨¡å‹
model = YOLO("path/to/YOLOv8n-SPTS.pt")

# å¯¹å›¾ç‰‡è¿›è¡Œé¢„æµ‹
results = model("path/to/image.jpg")

# æ˜¾ç¤ºç»“æœ
results[0].show()

# ä¿å­˜ç»“æœ
results[0].save("output.jpg")
```

##### è®­ç»ƒæ¨¡å‹

```python
from ultralytics import YOLO

# åŠ è½½æ¨¡å‹
model = YOLO("yolov8n.yaml")

# ä½¿ç”¨è‡ªå®šä¹‰æ•°æ®é›†è®­ç»ƒ
model.train(
    data="your_dataset.yaml",
    epochs=100,
    imgsz=640,
    batch=16
)
```

##### å‘½ä»¤è¡Œ

```bash
# é¢„æµ‹
yolo predict model=YOLOv8n-SPTS.pt source=image.jpg

# è®­ç»ƒ
yolo train model=yolov8n.yaml data=dataset.yaml epochs=100
```

### ğŸ“ é¡¹ç›®ç»“æ„

```
yolov8n-SPTS/
â”œâ”€â”€ ultralytics/
â”‚   â”œâ”€â”€ nn/
â”‚   â”‚   â”œâ”€â”€ CFFAttention.py      # CFF æ³¨æ„åŠ›æ¨¡å—
â”‚   â”‚   â”œâ”€â”€ ECAAttention.py      # ECA æ³¨æ„åŠ›æ¨¡å—
â”‚   â”‚   â”œâ”€â”€ SEAttention.py       # SE æ³¨æ„åŠ›æ¨¡å—
â”‚   â”‚   â””â”€â”€ ShuffleAttention.py  # Shuffle æ³¨æ„åŠ›æ¨¡å—
â”‚   â””â”€â”€ ...
â”œâ”€â”€ models/                       # é¢„è®­ç»ƒæ¨¡å‹ç›®å½•
â”œâ”€â”€ runs/detect/                  # è®­ç»ƒç»“æœ
â”œâ”€â”€ Train_model.py                # è®­ç»ƒè„šæœ¬
â””â”€â”€ README.md
```

### ğŸ”¬ æ³¨æ„åŠ›æœºåˆ¶è¯¦è§£

#### 1. CFF æ³¨æ„åŠ›ï¼ˆé€šé“ç‰¹å¾èåˆï¼‰
ç»“åˆæœ€å¤§æ± åŒ–å’Œå¹³å‡æ± åŒ–æ¥èåˆä¸åŒé€šé“çš„ç‰¹å¾ï¼Œç„¶ååº”ç”¨2Då·ç§¯è¿›è¡Œç‰¹å¾èåˆã€‚

#### 2. ECA æ³¨æ„åŠ›ï¼ˆé«˜æ•ˆé€šé“æ³¨æ„åŠ›ï¼‰
ä½¿ç”¨1Då·ç§¯è¿›è¡Œé«˜æ•ˆçš„é€šé“æ³¨æ„åŠ›è®¡ç®—ï¼Œåœ¨ä¿æŒæ€§èƒ½çš„åŒæ—¶å‡å°‘å‚æ•°é‡ã€‚

#### 3. SE æ³¨æ„åŠ›ï¼ˆæŒ¤å‹æ¿€åŠ±ï¼‰
ç»å…¸çš„æ³¨æ„åŠ›æœºåˆ¶ï¼Œä½¿ç”¨å…¨å±€å¹³å‡æ± åŒ–å’Œå…¨è¿æ¥å±‚æ¥å­¦ä¹ é€šé“çº§çš„æ³¨æ„åŠ›æƒé‡ã€‚

#### 4. Shuffle æ³¨æ„åŠ›
å°†ç‰¹å¾åˆ†ç»„ï¼Œåˆ†åˆ«åº”ç”¨é€šé“æ³¨æ„åŠ›å’Œç©ºé—´æ³¨æ„åŠ›ï¼Œç„¶åæ··æ´—é€šé“ä»¥å¢å¼ºä¿¡æ¯æµåŠ¨ã€‚

### ğŸ“ˆ æ€§èƒ½å¯¹æ¯”

| æ¨¡å‹ | mAP50 | mAP50-95 | å‚æ•°é‡ | FLOPs |
|-------|-------|----------|--------|-------|
| YOLOv8n | 37.3 | - | 3.2M | 8.7B |
| YOLOv8n-SPTS | **50.1** | **33.4** | - | - |

### ğŸ“ å¼•ç”¨

å¦‚æœæ‚¨åœ¨ç ”ç©¶ä¸­ä½¿ç”¨äº†æœ¬é¡¹ç›®ï¼Œè¯·è€ƒè™‘å¼•ç”¨ï¼š

```bibtex
@misc{yolov8n-spts,
  title={YOLOv8n-SPTS: YOLOv8 with Multiple Attention Mechanisms},
  author={Your Name},
  year={2024},
  howpublished={\url{https://github.com/SonghanWu/yolov8n-SPTS}}
}
```

### ğŸ“„ è®¸å¯è¯

æœ¬é¡¹ç›®åŸºäº [Ultralytics YOLOv8](https://github.com/ultralytics/ultralytics)ï¼Œéµå¾ª AGPL-3.0 è®¸å¯è¯ã€‚

### ğŸ™ è‡´è°¢

- [Ultralytics YOLOv8](https://github.com/ultralytics/ultralytics) æä¾›çš„åŸºç¡€æ¡†æ¶
- æ‰€æœ‰æ³¨æ„åŠ›æœºåˆ¶çš„è®ºæ–‡å’Œå®ç°

---

<div align="center">

**å¦‚æœè¿™ä¸ªé¡¹ç›®å¯¹æ‚¨æœ‰å¸®åŠ©ï¼Œè¯·ç»™ä¸ª â­ï¸ Star æ”¯æŒä¸€ä¸‹ï¼**

**If this project helps you, please give it a â­ï¸ Star!**

</div>
